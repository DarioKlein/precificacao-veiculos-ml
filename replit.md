# Projeto: Previs√£o de Pre√ßos de Ve√≠culos - Tabela FIPE

## Objetivo

Criar um algoritmo de machine learning capaz de prever pre√ßos de ve√≠culos **com base na tabela FIPE**.

## Status Atual

üü° **Progresso Parcial** - Conseguimos bons resultados, por√©m ainda longe do ideal que seria em torno de 95% de acur√°cia.

## Dados

- **Fonte**: https://www.kaggle.com/datasets/sandey/brazilian-vehicle-prices-june-2018-fipe
- **Registros**: 21.797 ve√≠culos
- **Features originais**: Marca, Ve√≠culo, Ano_Modelo, Pre√ßo de Refer√™ncia, Pre√ßo do Ve√≠culo.

## Resultados Obtidos

### Modelo Original - In√≠cio - Sem Pr√©-processamento

- Erro m√©dio - Rpart: **18-24%**
- Erro m√©dio - RandomForest: **32-41%**
- Erro m√©dio - SVM: **39-44%**

### Modelo Melhorado - Avan√ßo Parcial - Com Pr√©-processamento

- Erro m√©dio - Rpart: **11.26-12.92%** ‚úÖ Melhoria de ~12%!
- Tempo de execu√ß√£o: 0.31 Segundos

- Erro m√©dio - RandomForest: **12.38-14.66%** ‚úÖ Melhoria de ~27%!
- Tempo de execu√ß√£o:

- Erro m√©dio - SVM: **12.29-14.05%** ‚úÖ Melhoria de ~12%!
- Tempo de execu√ß√£o: 268.78 Segundos

## Features Engineering Implementadas

1. **Idade do ve√≠culo** (Calculada a partir do ano)
2. **Categorias de idade** (O ano de 2018 - O ano do ve√≠culo)
3. **Encoding de marcas** (Top 30-40 marcas, resto agrupado)
4. **Encoding de Nomes/Modelos** (Top 30-40 Nomes/Modelos, resto agrupado)
5. **Pre√ßo por cilindrada** (Efici√™ncia do motor)
6. **Ano num√©rico** (Em vez de categ√≥rico)
7. **C√¢mbio** (Manual ou Autom√°tico)

### üî∏ Features Espec√≠ficas para o SVM

8. **Cilindradas¬≤ (`Cilindradas_Quad`)** ‚Äî Captura efeitos n√£o lineares da cilindrada.
9. **Intera√ß√£o Idade √ó Cilindrada (`Idade_x_Cilindradas`)** ‚Äî Permite modelar a rela√ß√£o entre pot√™ncia e deprecia√ß√£o.
10. **Deprecia√ß√£o exponencial (`Deprec_Exp`)** ‚Äî simula a desvaloriza√ß√£o acelerada com o tempo.
11. **Categorias de cilindrada (`Cat_Cilindradas`)** ‚Äî divide motores em faixas (_Pequeno_, _M√©dio_, _Grande_, etc.).
12. **Flag Diesel (`Flag_Diesel`)** ‚Äî identifica ve√≠culos com combust√≠vel _Diesel_.
13. **Flag Autom√°tico (`Flag_Auto`)** ‚Äî identifica ve√≠culos com c√¢mbio _Autom√°tico_.

## Arquivos do Projeto

- `pre-processamento-I.r` - Primeira parte do pr√©-processamento realizado
- `pre-processamento-II.r` - Segunda parte do pr√©-processamento realizado
- `teste-com-random-forest.r` - Implementa√ß√£o da predi√ß√£o com o Modelo RandomForest
- `teste-com-rpart.r` - Implementa√ß√£o da predi√ß√£o com o Modelo Rpart (√Årvores de Decis√£o)
- `teste-com-svm.r` - Implementa√ß√£o da predi√ß√£o com o Modelo Support Vector Machine (SVM)
- `fipe.csv` - Base de dados FIPE - Original
- `TabelaFipeTransformada.csv` - Base de dados FIPE parcialmente pr√©-processada
- `TabelaFipeTransformadaV2.csv` - Base de dados FIPE - Finalizada

## Limita√ß√µes Identificadas

### Por que n√£o alcan√ßamos um resultado melhor, ou ao menos inferior a 10% em TODAS as previs√µes?

1. **Dados limitados**:

   - Faltam features importantes: **quilometragem**, **estado de conserva√ß√£o**, **regi√£o/cidade**
   - Ve√≠culos raros e outliers t√™m pouco dados para treinamento

2. **Modelos usados**:

   - Os modelos utilizados s√£o bons, mas as vers√µes utilizadas s√£o limitadas.
   - Algoritmos mais sofisticados (Ranger, XGBoost, LightGBM, CatBoost) provavelmente teriam melhor desempenho

3. **Problema de convers√£o**:

   - Imputa√ß√£o de valores faltantes usa m√©dia global (n√£o ideal)

4. **Sem otimiza√ß√£o sistem√°tica**:
   - Hiperpar√¢metros escolhidos manualmente
   - Grid Search ou valida√ß√£o cruzada provavelmente melhoraria os resultados

## Pr√≥ximos Passos para Alcan√ßar ‚â§5% de Erro

### Curto Prazo (podem ser feitos agora)

2. ‚úÖ Implementar XGBoost ou LightGBM
3. ‚úÖ Otimiza√ß√£o de hiperpar√¢metros com grid search
4. ‚úÖ Modelos espec√≠ficos por segmento (popular, m√©dio, luxo)

### M√©dio Prazo (requer mais dados)

5. üî¥ Adicionar quilometragem (n√£o dispon√≠vel na FIPE)
6. üî¥ Adicionar estado de conserva√ß√£o (n√£o dispon√≠vel na FIPE)
7. üî¥ Adicionar localiza√ß√£o/regi√£o (n√£o dispon√≠vel na FIPE)
8. üî¥ Adicionar dados de mercado real (an√∫ncios, vendas)

## üèÜ Melhor Algoritmo

Ap√≥s os testes e compara√ß√µes entre diferentes modelos de Machine Learning citados neste trabalho, o modelo que apresentou **melhor desempenho geral** foi o:

### üéØ **RPART (Recursive PARTitioning and Regression Trees)**

#### üîπ Motivos da Escolha:

- **Melhor performance em termos de erro m√©dio (MAE/RMSE)** nas previs√µes
- **Modelo simples e objetivo** utilizou a menor quantidade de vari√°veis e conseguiu ter o melhor desempenho
- **Generaliza√ß√£o superior** em rela√ß√£o a outros modelos, evitando overfitting
- **O modelo mais r√°pido que foi testado** em rela√ß√£o a outros modelos, que s√£o bem mais lentos

## Conclus√£o

**Alcan√ßamos melhorias substanciais** (de ~32% para ~12.5% de erro m√©dio), mas para chegar a **erro ‚â§ 5% em TODAS as previs√µes** precisar√≠amos:

- **Mais features** (dados que a tabela FIPE n√£o fornece)
- **Algoritmos mais sofisticados** (XGBoost, Deep Learning)
- **Modelos especializados** por segmento de mercado

A tabela FIPE, por si s√≥, tem limita√ß√µes porque fornece apenas pre√ßos tabelados m√©dios, sem considerar fatores como estado do ve√≠culo, quilometragem, e varia√ß√µes regionais.

## Recomenda√ß√£o

Para uso pr√°tico:

- ‚úÖ O modelo atual √© **muito bom para estimativas r√°pidas**
- ‚úÖ **~85% das previs√µes t√™m erro ‚â§ 10%** (aceit√°vel para muitos casos)
- ‚ö†Ô∏è Para decis√µes cr√≠ticas, considerar margem de erro de ~10-15%
- üéØ Para alcan√ßar ‚â§5% consistentemente, seria necess√°rio dados adicionais al√©m da FIPE

---

_√öltima atualiza√ß√£o: 02/11/2025_
